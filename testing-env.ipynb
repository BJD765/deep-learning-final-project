{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbc21959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 22 03:23:32 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 581.80                 Driver Version: 581.80         CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 5070 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   35C    P5             21W /   33W |       0MiB /  12227MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how to print nvidia-smi\n",
    "import subprocess\n",
    "def print_nvidia_smi():\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(result.stdout)\n",
    "        else:\n",
    "            print(\"Error executing nvidia-smi:\", result.stderr)\n",
    "    except FileNotFoundError:\n",
    "        print(\"nvidia-smi command not found. Make sure NVIDIA drivers are installed.\")\n",
    "if __name__ == \"__main__\":\n",
    "    print_nvidia_smi()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50760a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.9.1+cu130 | CUDA runtime: 13.0\n",
      "CUDA available: True\n",
      "Device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 5070 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA runtime:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current device:\", torch.cuda.current_device())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97669780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "step 0 | loss 1.0507\n",
      "step 1 | loss 0.8406\n",
      "step 2 | loss 0.5866\n",
      "step 3 | loss 0.3403\n",
      "step 4 | loss 0.1685\n",
      "Using device: cuda\n",
      "step 0 | loss 1.0527\n",
      "step 1 | loss 0.8470\n",
      "step 2 | loss 0.5899\n",
      "step 3 | loss 0.3480\n",
      "step 4 | loss 0.1731\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4096, 4096),\n",
    ").to(device)\n",
    "\n",
    "x = torch.randn(64, 4096, device=device)\n",
    "y = torch.randn(64, 4096, device=device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for step in range(5):\n",
    "    opt.zero_grad()\n",
    "    out = model(x)\n",
    "    loss = loss_fn(out, y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    print(f\"step {step} | loss {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4096, 4096),\n",
    ").to(device)\n",
    "\n",
    "x = torch.randn(64, 4096, device=device)\n",
    "y = torch.randn(64, 4096, device=device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for step in range(5):\n",
    "    opt.zero_grad()\n",
    "    out = model(x)\n",
    "    loss = loss_fn(out, y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    print(f\"step {step} | loss {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1b1516e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: torch.Size([64, 3, 32, 32]) torch.float32 device: cpu\n",
      "Moved to: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_ds = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "print(\"Batch:\", images.shape, images.dtype, \"device:\", images.device)\n",
    "\n",
    "images = images.to(device)\n",
    "print(\"Moved to:\", images.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a91d652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: c:\\Users\\ASUS\\Documents\\Deep Learning\n",
      "Using device: cuda\n",
      "Batch: torch.Size([64, 3, 32, 32]) torch.float32 device: cpu\n",
      "Moved to: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_ds = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "print(\"Batch:\", images.shape, images.dtype, \"device:\", images.device)\n",
    "\n",
    "images = images.to(device)\n",
    "print(\"Moved to:\", images.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da19baed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
